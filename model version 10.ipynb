{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d31285f-4ba0-4c62-8b5b-989fe569af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The purpose of this code is to process audio files in a specified directory, \n",
    "#segmenting each audio file into shorter audio clips of a predetermined duration, \n",
    "#and then save these segmented audio clips into a different directory.\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def segment_audio(audio_file, segment_duration=40): #The segment_audio function takes an audio file path and an optional segment_duration parameter, with a default value of 40 seconds.\n",
    "    try:\n",
    "        # Load audio file\n",
    "        audio, sr = librosa.load(audio_file, sr=None, mono=True)\n",
    "        \n",
    "        # Calculate the total number of segments\n",
    "        total_segments = len(audio) // (sr * segment_duration)\n",
    "        \n",
    "        segments = []\n",
    "        # Segment the audio file\n",
    "        for i in range(total_segments):\n",
    "            start_sample = i * sr * segment_duration\n",
    "            end_sample = start_sample + sr * segment_duration\n",
    "            segment = audio[start_sample:end_sample]\n",
    "            segments.append(segment)\n",
    "        \n",
    "        return segments, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error segmenting {audio_file}: {e}\")\n",
    "        return [], None\n",
    "\n",
    "# Directory containing the audio files\n",
    "data_directory = \"/Users/chamudi/Desktop/Dataset\"\n",
    "\n",
    "# Directory to save segmented audio files\n",
    "segmented_data_directory = \"/Users/chamudi/Desktop/Segmanted_Data_Model_10\"\n",
    "os.makedirs(segmented_data_directory, exist_ok=True)\n",
    "\n",
    "# Process each audio file\n",
    "for file in os.listdir(data_directory):\n",
    "    if file.endswith(\".mp3\"):\n",
    "        audio_path = os.path.join(data_directory, file)\n",
    "        segments, sr = segment_audio(audio_path)\n",
    "        if segments and sr:\n",
    "            # Save segmented audio files\n",
    "            for i, segment in enumerate(segments):\n",
    "                segment_file = f\"{os.path.splitext(file)[0]}_segment_{i}.wav\"\n",
    "                segment_path = os.path.join(segmented_data_directory, segment_file)\n",
    "                sf.write(segment_path, segment, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70f95fb-ce2e-4bfc-870e-ea6dabf12ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "def apply_stft(segment, sr, n_fft=2048, hop_length=512):\n",
    "    stft_result = librosa.stft(segment, n_fft=n_fft, hop_length=hop_length)\n",
    "    stft_magnitude = np.abs(stft_result)\n",
    "    stft_magnitude_db = librosa.amplitude_to_db(stft_magnitude, ref=np.max)\n",
    "    return stft_magnitude_db\n",
    "\n",
    "# Directory containing the audio files\n",
    "data_directory = \"/Users/chamudi/Desktop/Dataset\"\n",
    "\n",
    "# Directory to save features or processed data\n",
    "features_directory = \"/Users/chamudi/Desktop/Features_Data_Model_10\"\n",
    "os.makedirs(features_directory, exist_ok=True)\n",
    "\n",
    "# Process each audio file\n",
    "for file in os.listdir(data_directory):\n",
    "    if file.endswith(\".mp3\"):\n",
    "        audio_path = os.path.join(data_directory, file)\n",
    "        segments, sr = segment_audio(audio_path, segment_duration=40)\n",
    "        if segments and sr:\n",
    "            # Process and save features for each segment\n",
    "            for i, segment in enumerate(segments):\n",
    "                stft_features = apply_stft(segment, sr)\n",
    "                # Example feature processing or saving\n",
    "                feature_file = f\"{os.path.splitext(file)[0]}_segment_{i}_features.npy\"\n",
    "                feature_path = os.path.join(features_directory, feature_file)\n",
    "                np.save(feature_path, stft_features)\n",
    "\n",
    "print(\"Feature extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd8a24c-9cfd-4c36-ab68-cef995b5b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint generation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def load_stft_features(feature_path):\n",
    "    \"\"\"\n",
    "    Load STFT features from a .npy file.\n",
    "    \"\"\"\n",
    "    return np.load(feature_path)\n",
    "\n",
    "def find_peaks(stft_features, sr, n_fft, hop_length, pre_max, post_max, pre_avg, post_avg, delta, wait):\n",
    "    \"\"\"\n",
    "    Identify peaks in the STFT features using librosa's utilities.\n",
    "    \"\"\"\n",
    "    # Assuming stft_features is a 2D STFT matrix, you might first want to aggregate it into a 1D time series\n",
    "    # Here, we calculate the spectral flux as an example of such aggregation\n",
    "    spectral_flux = librosa.onset.onset_strength(S=stft_features, sr=sr)\n",
    "\n",
    "    # Use librosa's peak picking with keyword arguments\n",
    "    peaks = librosa.util.peak_pick(x=spectral_flux, pre_max=pre_max, post_max=post_max,\n",
    "                                   pre_avg=pre_avg, post_avg=post_avg, delta=delta, wait=wait)\n",
    "    return peaks\n",
    "\n",
    "# Directory where STFT features are stored\n",
    "features_directory = \"/Users/chamudi/Desktop/Features_Data_Model_10\"\n",
    "\n",
    "# Directory to save the fingerprints\n",
    "fingerprints_directory = \"/Users/chamudi/Desktop/Fingerprints_Data_Model_10\"\n",
    "os.makedirs(fingerprints_directory, exist_ok=True)\n",
    "\n",
    "# STFT parameters (should match those used during feature extraction)\n",
    "sr = 22050  # Sample rate\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "\n",
    "# Peak picking parameters\n",
    "pre_max = 1\n",
    "post_max = 1\n",
    "pre_avg = 3\n",
    "post_avg = 3\n",
    "delta = 0.2\n",
    "wait = 0\n",
    "\n",
    "# Process each STFT feature file\n",
    "for feature_file in os.listdir(features_directory):\n",
    "    if feature_file.endswith(\".npy\"):\n",
    "        feature_path = os.path.join(features_directory, feature_file)\n",
    "        stft_features = load_stft_features(feature_path)\n",
    "        \n",
    "        # Extract peaks as fingerprints\n",
    "        peaks = find_peaks(stft_features, sr, n_fft, hop_length, pre_max, post_max, pre_avg, post_avg, delta, wait)\n",
    "        \n",
    "        # Save fingerprints\n",
    "        fingerprint_file = feature_file.replace(\"_features.npy\", \"_fingerprints.npy\")\n",
    "        fingerprint_path = os.path.join(fingerprints_directory, fingerprint_file)\n",
    "        np.save(fingerprint_path, peaks)\n",
    "\n",
    "print(\"Fingerprint generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b279f2-ecc2-47d7-b1ab-8136c6ec06a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
