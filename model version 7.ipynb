{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8b67aab-f8c0-4cab-af80-92ebe1df360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /opt/anaconda3/lib/python3.11/site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.11/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ea94996-86b6-4af9-bfef-dcf7e8ffaf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import soundfile as sf  # Import soundfile library\n",
    "\n",
    "def segment_song(file_path, segment_length=40, save_segments=False, output_dir='segments'):\n",
    "    \"\"\"\n",
    "    Segment a song into fixed-length windows.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: Path to the audio file (e.g., 'path/to/song.mp3').\n",
    "    - segment_length: Length of each segment in seconds (e.g., 40).\n",
    "    - save_segments: Boolean, whether to save segments as separate audio files.\n",
    "    - output_dir: Directory where segmented audio files will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - segments: A list of audio arrays, each representing a segment.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Calculate the number of samples per segment\n",
    "    samples_per_segment = segment_length * sr\n",
    "    \n",
    "    # Number of segments\n",
    "    num_segments = int(np.floor(len(y) / samples_per_segment))\n",
    "    \n",
    "    segments = []\n",
    "    \n",
    "    for i in range(num_segments):\n",
    "        # Calculate start and end sample for the current segment\n",
    "        start_sample = i * samples_per_segment\n",
    "        end_sample = start_sample + samples_per_segment\n",
    "        \n",
    "        # Extract the segment\n",
    "        segment = y[start_sample:end_sample]\n",
    "        segments.append(segment)\n",
    "        \n",
    "        # Optionally save the segment to disk\n",
    "        if save_segments:\n",
    "            if not os.path.isdir(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            segment_filename = os.path.join(output_dir, f'segment_{i}.wav')\n",
    "            sf.write(segment_filename, segment, sr)  # Use soundfile to save the segment\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# Example usage\n",
    "file_path = '/Users/chamudi/Desktop/songs/train_data/1.mp3'\n",
    "segments = segment_song(file_path, segment_length=40, save_segments=True, output_dir='output_segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39ebeaa7-511c-44ba-a5a1-136da9340ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(segments, sr=22050, n_fft=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Extract STFT-based features from audio segments.\n",
    "    \n",
    "    Parameters:\n",
    "    - segments: List of audio segments.\n",
    "    - sr: Sampling rate of the audio segments.\n",
    "    - n_fft: Number of FFT components.\n",
    "    - hop_length: Number of samples between successive frames.\n",
    "    \n",
    "    Returns:\n",
    "    - fingerprints: A list of magnitude spectrograms (audio fingerprints) for each segment.\n",
    "    \"\"\"\n",
    "    fingerprints = []\n",
    "    for segment in segments:\n",
    "        # Compute the STFT\n",
    "        stft = librosa.stft(segment, n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "        # Compute the magnitude spectrogram from the STFT\n",
    "        spectrogram = np.abs(stft)\n",
    "        \n",
    "        # Convert to decibel units for a more dynamic range\n",
    "        db_spectrogram = librosa.amplitude_to_db(spectrogram, ref=np.max)\n",
    "        \n",
    "        fingerprints.append(db_spectrogram)\n",
    "    \n",
    "    return fingerprints\n",
    "\n",
    "# Example usage assuming 'segments' is a list of audio segments from the previous step\n",
    "fingerprints = extract_features(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82479943-e391-48d7-9086-fdc9d1beaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data initialization for demonstration purposes\n",
    "fingerprints = np.random.rand(100, 128, 44, 1)  # Example shape, adjust as necessary\n",
    "song_ids = np.random.randint(0, 10, size=100)   # Assuming 10 unique songs for 100 fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "541693c8-2c38-4960-9d06-d9dbbf04aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(fingerprints, song_ids):\n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "    labels = []\n",
    "\n",
    "    # Generate positive pairs\n",
    "    for i in range(len(fingerprints)):\n",
    "        for j in range(i+1, len(fingerprints)):\n",
    "            if song_ids[i] == song_ids[j]:\n",
    "                positive_pairs.append([fingerprints[i], fingerprints[j]])\n",
    "                labels.append(1)\n",
    "    \n",
    "    # Generate negative pairs (simplified approach)\n",
    "    for i in range(len(positive_pairs)):  # Generating as many negative pairs as positive\n",
    "        while True:\n",
    "            idx1, idx2 = np.random.randint(0, len(fingerprints), size=2)\n",
    "            if song_ids[idx1] != song_ids[idx2]:\n",
    "                negative_pairs.append([fingerprints[idx1], fingerprints[idx2]])\n",
    "                labels.append(0)\n",
    "                break\n",
    "    \n",
    "    # Combine positive and negative pairs\n",
    "    pairs = positive_pairs + negative_pairs\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67382f07-d3e5-48b9-84f3-647aec52e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs, labels = generate_pairs(fingerprints, song_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "853fe156-ec65-4638-af6e-396d4259d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of splitting (adjust indices according to your dataset size and needs)\n",
    "split_point = int(len(pairs) * 0.8)\n",
    "pairs_train, labels_train = pairs[:split_point], labels[:split_point]\n",
    "pairs_val, labels_val = pairs[split_point:], labels[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fd89ab1-d65e-4d72-b69e-9908546a505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dummy initialization of fingerprints and their corresponding song IDs\n",
    "# Replace this with actual loading or generation of your dataset\n",
    "fingerprints = np.random.rand(100, 128, 44, 1)  # 100 random fingerprints\n",
    "song_ids = np.random.randint(0, 10, 100)       # 100 random song IDs ranging from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02236b51-a06d-4aa3-9415-03e88a85cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(fingerprints, song_ids):\n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "    labels = []\n",
    "\n",
    "    # Example logic to generate positive and negative pairs\n",
    "    for i in range(len(fingerprints)):\n",
    "        for j in range(i + 1, len(fingerprints)):\n",
    "            if song_ids[i] == song_ids[j]:\n",
    "                positive_pairs.append([fingerprints[i], fingerprints[j]])\n",
    "                labels.append(1)  # Similar\n",
    "            else:\n",
    "                if len(negative_pairs) < len(positive_pairs):  # To balance the dataset\n",
    "                    negative_pairs.append([fingerprints[i], fingerprints[j]])\n",
    "                    labels.append(0)  # Dissimilar\n",
    "\n",
    "    pairs = np.array(positive_pairs + negative_pairs)\n",
    "    labels = np.array(labels)\n",
    "    return pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f202a96-eb68-47e6-bcfc-ea507410172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs, labels = generate_pairs(fingerprints, song_ids)  # Use the actual function to generate pairs\n",
    "\n",
    "# Shuffle and split the dataset into training and validation sets\n",
    "indices = np.arange(len(pairs))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split_point = int(len(pairs) * 0.8)  # 80% for training, 20% for validation\n",
    "train_indices = indices[:split_point]\n",
    "val_indices = indices[split_point:]\n",
    "\n",
    "pairs_train, labels_train = pairs[train_indices], labels[train_indices]\n",
    "pairs_val, labels_val = pairs[val_indices], labels[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "406c471d-633e-4b9c-946b-6cc634961643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,498,304</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m44\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m44\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m4,498,304\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ functional_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_9[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m2\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,498,306</span> (17.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,498,306\u001b[0m (17.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,498,306</span> (17.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,498,306\u001b[0m (17.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    \"\"\"\n",
    "    Base network to be shared (eq. to feature extraction).\n",
    "    \"\"\"\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"\n",
    "    Compute Euclidean Distance between two vectors.\n",
    "    \"\"\"\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    \"\"\"\n",
    "    Shape of the output of the Euclidean distance layer.\n",
    "    \"\"\"\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "# Define the tensors for the two input images\n",
    "input_shape = (128, 44, 1)  # Example input shape, adjust based on your fingerprint shape\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# Because we re-use the same instance `base_network`,\n",
    "# the weights of the network will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# Use a Lambda layer to compute the absolute difference between the feature vectors\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "# Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "prediction = Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "# Connect the inputs with the outputs\n",
    "model = Model(inputs=[input_a, input_b], outputs=prediction)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26c152ab-5efa-4e62-aeb5-b8427087723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "733ec676-d3ca-44a7-8b62-6cf6a22b9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'User/chamudi/Desktop/weights.weights.h5'  # Adjusted extension\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c2c16f4-e5fd-4c94-8c7c-394bf709e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'User/chamudi/Desktop/model.keras'  # Updated extension for full model saving\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,  # Saving the entire model\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a7bc479-0af0-4bd9-aa1a-29b2872d54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fdf6aec-2b3e-4681-ae10-0c792712e112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - accuracy: 0.4818 - loss: 0.6952 - val_accuracy: 0.4787 - val_loss: 0.7029\n",
      "Epoch 2/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 0.5143 - loss: 0.6797 - val_accuracy: 0.4787 - val_loss: 0.7183\n",
      "Epoch 3/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - accuracy: 0.5209 - loss: 0.6638 - val_accuracy: 0.4787 - val_loss: 0.7293\n",
      "Epoch 4/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 0.4919 - loss: 0.6604 - val_accuracy: 0.4787 - val_loss: 0.7316\n",
      "Epoch 5/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - accuracy: 0.5232 - loss: 0.6427 - val_accuracy: 0.4787 - val_loss: 0.7365\n",
      "Epoch 6/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 0.5137 - loss: 0.6388 - val_accuracy: 0.4787 - val_loss: 0.7390\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [pairs_train[:, 0], pairs_train[:, 1]],  # Assuming pairs_train is structured to allow this indexing\n",
    "    labels_train,\n",
    "    validation_data=([pairs_val[:, 0], pairs_val[:, 1]], labels_val),\n",
    "    epochs=20,  # Adjust based on your needs\n",
    "    batch_size=64,  # Adjust based on your needs\n",
    "    callbacks=[model_checkpoint_callback, early_stopping_callback],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "833874f3-c530-4f39-9ea7-d2bb2d0647f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5639 - loss: 0.6918\n",
      "Test Loss: 0.6956056356430054\n",
      "Test Accuracy: 0.5400000214576721\n"
     ]
    }
   ],
   "source": [
    "# Generate dummy test data (assuming your inputs are images of shape 128x44x1)\n",
    "import numpy as np\n",
    "\n",
    "num_test_samples = 100\n",
    "pairs_test = np.random.rand(num_test_samples, 2, 128, 44, 1)  # 100 pairs of test fingerprints\n",
    "labels_test = np.random.randint(0, 2, num_test_samples)       # 100 random binary labels\n",
    "\n",
    "# Convert the dummy test data into the correct format\n",
    "left_input_test = np.array([pair[0] for pair in pairs_test])\n",
    "right_input_test = np.array([pair[1] for pair in pairs_test])\n",
    "\n",
    "# Evaluate the model on the dummy test data\n",
    "test_loss, test_accuracy = model.evaluate([left_input_test, right_input_test], labels_test, verbose=1)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7be075b0-498c-46d7-a924-c9b2cca8b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5639 - loss: 0.6918\n",
      "Test Loss: 0.6956056356430054\n",
      "Test Accuracy: 0.5400000214576721\n"
     ]
    }
   ],
   "source": [
    "# Assuming pairs_test and labels_test are your test dataset prepared similarly to training data\n",
    "test_loss, test_accuracy = model.evaluate([pairs_test[:, 0], pairs_test[:, 1]], labels_test, verbose=1)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ed35b17-c402-4008-9803-9b4b0ba1b5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming left_input_test and right_input_test are your test inputs\n",
    "predictions = model.predict([left_input_test, right_input_test])\n",
    "\n",
    "# Binarize predictions based on a 0.5 threshold\n",
    "binary_predictions = (predictions > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ba862d8-fd0d-42b3-b2b0-5e0a8bdf47f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming labels_test are your true binary labels\n",
    "precision = precision_score(labels_test, binary_predictions)\n",
    "recall = recall_score(labels_test, binary_predictions)\n",
    "f1 = f1_score(labels_test, binary_predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42ee98-048c-45d4-8357-a568cabcc604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
