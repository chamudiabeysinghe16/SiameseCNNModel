{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a45dc4d-13cb-4fac-a812-976a85c01d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def segment_song(file_path, segment_duration=40, overlap=0):\n",
    "    \"\"\"\n",
    "    Segment a song into fixed-length windows.\n",
    "\n",
    "    Args:\n",
    "    - file_path: Path to the MP3 file.\n",
    "    - segment_duration: Duration of each segment in seconds.\n",
    "    - overlap: Overlap between segments in seconds.\n",
    "\n",
    "    Returns:\n",
    "    - segments: List of audio segments.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)  # Load with the native sampling rate\n",
    "    \n",
    "    # Calculate the number of samples per segment\n",
    "    samples_per_segment = segment_duration * sr\n",
    "    \n",
    "    # Calculate the hop length if overlap is specified\n",
    "    hop_length = int((1 - overlap) * samples_per_segment)\n",
    "    \n",
    "    # Initialize the list to hold segments\n",
    "    segments = []\n",
    "    \n",
    "    # Generate segments with the specified overlap\n",
    "    for start in range(0, len(y) - samples_per_segment + 1, hop_length):\n",
    "        end = start + samples_per_segment\n",
    "        segments.append(y[start:end])\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# Example: Process all MP3 files in a directory\n",
    "directory = '/Users/chamudi/Desktop/songs/train_data/10.mp3'\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp3'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            # Segment each song with a specific overlap, e.g., 50% overlap\n",
    "            segments = segment_song(file_path, overlap=0.5)\n",
    "            # Further processing such as feature extraction can go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f4af2e-2e4a-4276-9e42-e1cd4e47a705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_audio(file_path, target_sr=22050, mono=True):\n",
    "    \"\"\"\n",
    "    Load an audio file, ensuring uniform sample rate and mono channel.\n",
    "\n",
    "    Args:\n",
    "    - file_path: Path to the audio file.\n",
    "    - target_sr: Target sampling rate.\n",
    "    - mono: Convert audio to mono.\n",
    "\n",
    "    Returns:\n",
    "    - y: Audio time series.\n",
    "    - sr: Sampling rate of `y`.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=target_sr, mono=mono)\n",
    "    return y, sr\n",
    "\n",
    "def extract_stft_features(audio_segments, sr, n_fft=2048, hop_length=512, win_length=None):\n",
    "    \"\"\"\n",
    "    Extract STFT features from audio segments.\n",
    "\n",
    "    Args:\n",
    "    - audio_segments: List of audio segments.\n",
    "    - sr: Sampling rate.\n",
    "    - n_fft: Length of the FFT window.\n",
    "    - hop_length: Number of samples between successive frames.\n",
    "    - win_length: Each frame of audio is windowed by `window()` of length `win_length`.\n",
    "\n",
    "    Returns:\n",
    "    - stft_features: List of STFT matrices for each segment.\n",
    "    \"\"\"\n",
    "    stft_features = [librosa.stft(segment, n_fft=n_fft, hop_length=hop_length, win_length=win_length) for segment in audio_segments]\n",
    "    return stft_features\n",
    "\n",
    "# Example usage for a single MP3 file\n",
    "file_path = '/Users/chamudi/Desktop/songs/train_data/10.mp3'\n",
    "audio, sr = preprocess_audio(file_path)\n",
    "\n",
    "# Assuming you have segmented your audio as described in the previous step\n",
    "# For demonstration, here's how you might segment the preprocessed audio\n",
    "segment_duration = 40  # seconds\n",
    "samples_per_segment = segment_duration * sr\n",
    "audio_segments = [audio[i:i+samples_per_segment] for i in range(0, len(audio), samples_per_segment)]\n",
    "\n",
    "# Extract STFT features for each segment\n",
    "stft_features = extract_stft_features(audio_segments, sr)\n",
    "\n",
    "# At this point, `stft_features` contains the STFT matrices for each audio segment\n",
    "# You might want to further process these (e.g., magnitude, power spectrum) before storage or analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d882fe5-2bde-4647-b6bb-e4dde1da4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def initialize_base_network(input_shape):\n",
    "    \"\"\"\n",
    "    Define the base network (convolutional neural network, for example) to be used within the Siamese architecture.\n",
    "    \"\"\"\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    \"\"\"\n",
    "    Compute Euclidean distance between two vectors.\n",
    "    \"\"\"\n",
    "    vector1, vector2 = vectors\n",
    "    sum_square = K.sum(K.square(vector1 - vector2), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def euclidean_distance_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "# Assuming fingerprint shape is (128, 128, 1) for example\n",
    "input_shape = (128, 128, 1)\n",
    "\n",
    "# Initialize base network\n",
    "base_network = initialize_base_network(input_shape)\n",
    "\n",
    "# Create the left input and point to the base network\n",
    "input_a = Input(shape=input_shape)\n",
    "processed_a = base_network(input_a)\n",
    "\n",
    "# Create the right input and point to the base network\n",
    "input_b = Input(shape=input_shape)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# Compute the Euclidean distance between the two vector outputs\n",
    "distance = Lambda(euclidean_distance, output_shape=euclidean_distance_output_shape)([processed_a, processed_b])\n",
    "\n",
    "# Define the model to take the two inputs and output their distance\n",
    "model = Model([input_a, input_b], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bcbb0f1-57f6-4f49-a7b7-142dde66f8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - loss: 0.3039\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.1340\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0410\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0248\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0130\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0076\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0042\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0023\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0015\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c2b97e10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example data structure for pairs_train\n",
    "# pairs_train shape: (number_of_pairs, 2, height, width, channels)\n",
    "# For simplicity, assuming each fingerprint is 128x128 with 1 channel (grayscale)\n",
    "# This is just a conceptual structure; you'll need to replace it with your actual data loading logic\n",
    "\n",
    "# Simulated data\n",
    "number_of_pairs = 1000  # This should be the actual number of pairs you have\n",
    "height, width, channels = 128, 128, 1  # Adjust based on your fingerprint dimensions\n",
    "pairs_train = np.random.rand(number_of_pairs, 2, height, width, channels)\n",
    "\n",
    "# Labels: 1 for matching pairs, 0 for non-matching pairs\n",
    "labels_train = np.random.randint(2, size=(number_of_pairs,))\n",
    "\n",
    "# Now you can use pairs_train and labels_train in model.fit()\n",
    "# Ensure you replace the random data generation with your actual data loading and preprocessing\n",
    "model.fit([pairs_train[:, 0], pairs_train[:, 1]], labels_train, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6a1b6b-9e77-4c07-803b-8be88c06174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - loss: 0.0034\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.1433\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0499\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0228\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0113\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0080\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0054\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0035\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0021\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c2c8bc90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    \"\"\"\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "model.compile(optimizer='adam', loss=contrastive_loss)\n",
    "\n",
    "# Assume `pairs_train` and `labels_train` contain your training data and labels, respectively\n",
    "model.fit([pairs_train[:, 0], pairs_train[:, 1]], labels_train, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d10ed0-39d7-4f0b-8196-de42dfe71ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def generate_query_fingerprint(file_path, sr=22050):\n",
    "    y, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "    S = librosa.stft(y)\n",
    "    fingerprint = np.abs(S)  # Use magnitude for simplicity\n",
    "    return fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27fac856-3f5a-4c0c-bacd-6a3f480062fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_song(query_fingerprint, siamese_model, threshold=0.5):\n",
    "    # Placeholder for database retrieval logic\n",
    "    stored_fingerprints = load_fingerprints_from_database()  # Implement this based on your database schema\n",
    "    \n",
    "    for stored_fingerprint in stored_fingerprints:\n",
    "        # Assuming stored_fingerprint is preprocessed similarly to the training data\n",
    "        # Calculate the distance or similarity score using the Siamese model\n",
    "        distance = siamese_model.predict([np.expand_dims(query_fingerprint, axis=0), np.expand_dims(stored_fingerprint, axis=0)])\n",
    "        \n",
    "        if distance < threshold:  # Adjust threshold based on your validation results\n",
    "            return True, stored_fingerprint['song_id']  # Assume each fingerprint includes song_id reference\n",
    "    \n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee234e0-b497-4b88-8c22-e1d4ffb2555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "# Other necessary imports...\n",
    "\n",
    "# Define your Siamese CNN architecture here...\n",
    "def create_siamese_model():\n",
    "    # Model definition...\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "trained_siamese_model = create_siamese_model()\n",
    "\n",
    "# Compile the model\n",
    "trained_siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Assume you have your training data prepared as pairs and labels\n",
    "# pairs_train, labels_train = ...\n",
    "\n",
    "# Train the model\n",
    "# trained_siamese_model.fit([pairs_train[:, 0], pairs_train[:, 1]], labels_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Now trained_siamese_model is defined and can be used for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42bd7875-cbe0-499b-b206-60a1d273b75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m181.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1628940a-bc04-4433-a767-a0693bdbbcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def load_fingerprints_from_database_sqlite(db_path='your_database_file.db'):\n",
    "    fingerprints = []\n",
    "    # Connect to the SQLite database\n",
    "    connection = sqlite3.connect(db_path)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Adjust the SQL query for SQLite, if necessary\n",
    "    cursor.execute(\"SELECT fingerprint, song_id FROM Fingerprints\")\n",
    "\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        # Deserialize fingerprint (if necessary)\n",
    "        fingerprint = pickle.loads(row[0])\n",
    "        song_id = row[1]\n",
    "        fingerprints.append((fingerprint, song_id))\n",
    "\n",
    "    connection.close()\n",
    "    return fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12ee44a2-31d7-47f4-9f8a-4398311593fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def load_fingerprints_from_database():\n",
    "    # Placeholder list to store the fingerprints retrieved from the database\n",
    "    fingerprints = []\n",
    "    \n",
    "    # Connect to the database\n",
    "    connection = pymysql.connect(host='your_host',\n",
    "                                 user='your_user',\n",
    "                                 password='your_password',\n",
    "                                 database='your_database',\n",
    "                                 charset='utf8mb4',\n",
    "                                 cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # SQL query to select fingerprints (and any other relevant info)\n",
    "            # Adjust the SQL based on your schema\n",
    "            sql = \"SELECT fingerprint, song_id FROM Fingerprints\"\n",
    "            cursor.execute(sql)\n",
    "            \n",
    "            # Fetch all the rows\n",
    "            rows = cursor.fetchall()\n",
    "            \n",
    "            for row in rows:\n",
    "                # Assuming the fingerprints are stored as BLOBs and need to be deserialized\n",
    "                fingerprint = pickle.loads(row['fingerprint'])\n",
    "                song_id = row['song_id']\n",
    "                \n",
    "                # Append a tuple of deserialized fingerprint and song_id to the list\n",
    "                fingerprints.append((fingerprint, song_id))\n",
    "                \n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "    return fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa3ccb74-80c2-4838-bc3f-e027199ee3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(2003, \"Can't connect to MySQL server on 'your_host' ([Errno 8] nodename nor servname provided, or not known)\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pymysql/connections.py:644\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     sock \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    645\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect_timeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    646\u001b[0m     )\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/socket.py:827\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    826\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m getaddrinfo(host, port, \u001b[38;5;241m0\u001b[39m, SOCK_STREAM):\n\u001b[1;32m    828\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[1;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     12\u001b[0m query_fingerprint \u001b[38;5;241m=\u001b[39m generate_query_fingerprint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/chamudi/Desktop/songs/train_data/7.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m match_found, song_id \u001b[38;5;241m=\u001b[39m find_matching_song(query_fingerprint, trained_siamese_model)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match_found:\n\u001b[1;32m     16\u001b[0m     song_details \u001b[38;5;241m=\u001b[39m retrieve_song_details(song_id)\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mfind_matching_song\u001b[0;34m(query_fingerprint, siamese_model, threshold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_matching_song\u001b[39m(query_fingerprint, siamese_model, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Placeholder for database retrieval logic\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     stored_fingerprints \u001b[38;5;241m=\u001b[39m load_fingerprints_from_database()  \u001b[38;5;66;03m# Implement this based on your database schema\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stored_fingerprint \u001b[38;5;129;01min\u001b[39;00m stored_fingerprints:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# Assuming stored_fingerprint is preprocessed similarly to the training data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# Calculate the distance or similarity score using the Siamese model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         distance \u001b[38;5;241m=\u001b[39m siamese_model\u001b[38;5;241m.\u001b[39mpredict([np\u001b[38;5;241m.\u001b[39mexpand_dims(query_fingerprint, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), np\u001b[38;5;241m.\u001b[39mexpand_dims(stored_fingerprint, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)])\n",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m, in \u001b[0;36mload_fingerprints_from_database\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m fingerprints \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Connect to the database\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m connection \u001b[38;5;241m=\u001b[39m pymysql\u001b[38;5;241m.\u001b[39mconnect(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_host\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                              user\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_user\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m                              password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_password\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m                              database\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_database\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m                              charset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8mb4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                              cursorclass\u001b[38;5;241m=\u001b[39mpymysql\u001b[38;5;241m.\u001b[39mcursors\u001b[38;5;241m.\u001b[39mDictCursor)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cursor:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# SQL query to select fingerprints (and any other relevant info)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# Adjust the SQL based on your schema\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pymysql/connections.py:358\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pymysql/connections.py:711\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mprint\u001b[39m(exc\u001b[38;5;241m.\u001b[39mtraceback)\n\u001b[0;32m--> 711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If e is neither DatabaseError or IOError, It's a bug.\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# But raising AssertionError hides original error.\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# So just reraise it.\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (2003, \"Can't connect to MySQL server on 'your_host' ([Errno 8] nodename nor servname provided, or not known)\")"
     ]
    }
   ],
   "source": [
    "def retrieve_song_details(song_id):\n",
    "    # Placeholder for database query logic\n",
    "    song_details = query_database_for_song_details(song_id)  # Implement this based on your database schema\n",
    "    return song_details\n",
    "\n",
    "def log_song_occurrence(song_details, timestamp, broadcast_details):\n",
    "    # Implement logging logic here\n",
    "    # This could involve writing to a file, sending to a logging service, etc.\n",
    "    print(f\"Match found: {song_details} at {timestamp} during {broadcast_details}\")\n",
    "\n",
    "# Example usage\n",
    "query_fingerprint = generate_query_fingerprint('/Users/chamudi/Desktop/songs/train_data/7.mp3')\n",
    "match_found, song_id = find_matching_song(query_fingerprint, trained_siamese_model)\n",
    "\n",
    "if match_found:\n",
    "    song_details = retrieve_song_details(song_id)\n",
    "    log_song_occurrence(song_details, '2024-03-13 12:34:56', 'Example Radio Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3e74e-a1f7-4a2f-b3ff-cc8438c39927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
